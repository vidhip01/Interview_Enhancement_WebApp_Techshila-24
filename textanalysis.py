# -*- coding: utf-8 -*-
"""TextAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CLkAMHQopSBOhPO1uj12UXeV30gm4sIX
"""

!pip install pytube
import pytube

#extracting audio from video youtube link
video= 'https://www.youtube.com/shorts/f2bz0-HS7Ho'
data=pytube.YouTube(video)
audio=data.streams.get_audio_only()
A=audio.download()
Aud=A[9:]
Aud

!pip install --force-reinstall git+https://github.com/openai/whisper.git -q

import whisper

#Loading large model
model1 = whisper.load_model('large')
decode_options={"language":"english"}
text = model1.transcribe(Aud,word_timestamps= True,verbose=True)

!pip install tqdm

from google.colab import drive
drive.mount("/content/drive/")

!pip install nltk language_tool_python PyDictionary

file_path = "transcribed_text.txt"
with open(file_path, "w") as file:
    file.write(str(text))

import language_tool_python

def check_grammar(text):
    tool = language_tool_python.LanguageTool('en-US')
    matches = tool.check(text)
    for match in matches:
        print(match)

check_grammar(text)

!pip install -q -U google-generativeai

import pathlib
import textwrap

import google.generativeai as genai

from IPython.display import display
from IPython.display import Markdown


def to_markdown(text):
  text = text.replace('â€¢', '  *')
  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))

# Used to securely store your API key
from google.colab import userdata

import os
os.environ['GOOGLE_API_KEY']="AIzaSyAvVS3R25nh7cENucohKlkJiOuxscENNtA"

genai.configure(api_key=os.environ['GOOGLE_API_KEY'])

for m in genai.list_models():
  if 'generateContent' in m.supported_generation_methods:
    print(m.name)

model = genai.GenerativeModel('gemini-1.0-pro-latest')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# response = model.generate_content("Suggest some feedback and improvements, positives, negatives, better action words in short to the person who is ansering this interview question"+ str(text) )

to_markdown(response.text)

response.prompt_feedback



